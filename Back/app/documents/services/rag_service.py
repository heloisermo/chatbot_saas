"""
Service RAG - Retrieval Augmented Generation
"""
from typing import List, Dict

from app.documents.services.document_indexer import DocumentIndexer
from app.documents.services.mistral_service import MistralService


class RAGService:
    """Service pour les requ√™tes RAG (Retrieval + Generation)"""
    
    def __init__(self, indexer: DocumentIndexer):
        """
        Initialise le service RAG
        
        Args:
            indexer: Instance du DocumentIndexer
        """
        self.indexer = indexer
        self.mistral = MistralService()
    
    def query(self, question: str, k: int = 4, system_prompt: str = None) -> Dict:
        """
        Effectue une requ√™te RAG
        
        Args:
            question: Question de l'utilisateur
            k: Nombre de documents √† r√©cup√©rer
            system_prompt: Prompt syst√®me personnalis√© (optionnel)
            
        Returns:
            Dictionnaire avec la r√©ponse et les sources
        """
        if self.indexer.vector_store is None:
            return {
                "answer": "Aucun document n'a √©t√© index√©. Veuillez d'abord uploader des documents.",
                "sources": []
            }
        
        # R√©cup√©rer les documents pertinents
        docs_with_scores = self.indexer.search(question, k=k)
        
        # LOG: Afficher ce qui a √©t√© trouv√©
        print("\n" + "="*80)
        print(f"üîé RECHERCHE DANS L'INDEX: '{question}'")
        print(f"üìä Nombre de documents trouv√©s: {len(docs_with_scores)}")
        print("="*80)
        for i, (doc, score) in enumerate(docs_with_scores):
            print(f"\nDocument {i+1} (score: {score:.4f}):")
            print(f"Contenu: {doc.page_content[:200]}...")
            print(f"M√©tadonn√©es: {doc.metadata}")
        print("="*80 + "\n")
        
        if not docs_with_scores:
            return {
                "answer": "Je n'ai pas trouv√© d'informations pertinentes dans les documents index√©s.",
                "sources": []
            }
        
        # Pr√©parer le contexte
        context = "\n\n".join([
            f"Document {i+1}:\n{doc.page_content}" 
            for i, (doc, _) in enumerate(docs_with_scores)
        ])
        
        # Obtenir la r√©ponse du LLM via Mistral
        answer = self.mistral.generate_response(context, question, system_prompt=system_prompt)
        
        # Pr√©parer les sources
        sources = []
        for i, (doc, score) in enumerate(docs_with_scores):
            sources.append({
                "content": doc.page_content[:200] + "...",
                "metadata": doc.metadata,
                "score": float(score),
                "index": i + 1
            })
        
        return {
            "answer": answer,
            "sources": sources,
            "question": question
        }
    
    def chat(self, messages: List[Dict[str, str]], k: int = 4) -> Dict:
        """
        Conversation multi-tour avec contexte RAG
        
        Args:
            messages: Liste de messages [{role: "user/assistant", content: "..."}]
            k: Nombre de documents √† r√©cup√©rer
            
        Returns:
            Dictionnaire avec la r√©ponse et les sources
        """
        # Prendre la derni√®re question de l'utilisateur
        user_messages = [m for m in messages if m.get("role") == "user"]
        if not user_messages:
            return {
                "answer": "Aucune question d√©tect√©e.",
                "sources": []
            }
        
        last_question = user_messages[-1]["content"]
        
        # Utiliser la m√©thode query standard
        return self.query(last_question, k=k)
